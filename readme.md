# 自动化om模型转换

#### 使用前请参考本文档

#### Written by whypoxic

##

### 本项目适用`海思系列`/`昇腾npu`算力开发板

*使用开发板时，请及时查看该板卡所支持的昇腾驱动包版本，从算力板官方资料或昇腾官方获取Ascend-toolkit工具包，并将你的工具包替换`Ascend`目录下的驱动包内容*

*Ascend-toolkit工具包获取可查看本目录下的 `安装昇腾工具包指南.md`*

### 本项目提供自动化脚本，用于将 `.onnx` 神经网络模型 转化为 `.om` 适配昇腾平台的模型

*若使用yolo(`.pt`)或其他模型，需要先转化为`.onnx`通用模型；*

*以yolo模型为例，yolo官方提供`export.py`用于`.onnx`的模型转化*

##

**已经提供好自动化脚本，可供直接运行。**

### 运行前，需要将需要转换的`.onnx`模型放入`run`目录下

*（脚本会进行conda环境的创建，因此建议提前安装好`miniconda`；若没有，脚本会自动安装）*

*（项目初始提供了一个`test.onnx`用于测试，实际使用请替换）*

在当前目录下，进入终端赋予脚本运行权限，执行脚本：
```
chmod +x all-run.sh

./all-run.sh test.onnx out
```

**脚本需要两个参数输入：第一个是`run`目录下的`onnx`模型文件名（需要后缀）；第二个是生成`om`文件的命名。**

- 脚本会执行conda环境的创建，新建一个`atc`的conda环境，安装指定版本的python与相应包。

- 在该环境下，使用昇腾工具包下的atc工具执行转换。

转换完成后，生成的`.om`文件会在`run`目录下生成。

##

若自动化脚本出现异常，或者需要手动修改部分参数，可以使用命令行进行手动调用来执行转换。

命令行全过程操作参考本目录下的：`手动转换指南.md`

##





